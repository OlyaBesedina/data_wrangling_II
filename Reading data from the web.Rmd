---
title: "Reading data from the web"
author: "Olya Besedina"
data: "10/10/2019"
output: github_document
---
  
```{r setup, include=FALSE}

library(tidyverse)
library(rvest)
library(httr)


knitr::opts_chunk$set(
 	echo = TRUE,
 	warning = FALSE,
 	fig.width = 8, 
   fig.height = 6,
   out.width = "90%"
 )

options(
   ggplot2.continuous.colour = "viridis",
   ggplot2.continuous.fill = "viridis"
 )

 scale_colour_discrete = scale_colour_viridis_d
 scale_fill_discrete = scale_fill_viridis_d

 theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# get the data
```{r, eval = FALSE}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_xml = read_html(url)

drug_use_xml %>% 
  html_nodes(css = "table")

# now you have all 15 tables, but you want just the first one

drug_use_xml %>% 
  html_nodes(css = "table")%>% 
  .[[1]]

# the same as 
  table_list = drug_use_xml %>% 
 html_nodes(css = "table") 
  table_list = [[1]]

```

.[[1]] extracts the first table
dot before the brackets = everything that was before the pipe now represented by the dot
table_list is the same as .

```{r, eval =FALSE}
table_marj = 
  (drug_use_xml %>% html_nodes(css = "table")) %>% 
  .[[1]] %>%
  html_table() %>%
  slice(-1) %>% 
  as_tibble()
```

# extract table kfrom teh web
```{r}
nyc_cost = 
  read_html("https://www.bestplaces.net/cost_of_living/city/new_york/new_york") %>%
  html_nodes(css = "table") %>%
  .[[1]] %>%
  html_table(header = TRUE)
```

# harry potter data

```{r}
hpsaga_html = 
  read_html("https://www.imdb.com/list/ls000630791/")

```

```{r eval = FALSE}
hp_movie_names =
  hpsaga_html %>% 
    html_nodes(".lister-item-header a") %>%
  html_text()

hp_movies_runtime = 
  hpsaga_html %>% 
  html_nodes(".runtime") %>% 
  html_text()

hp_df = 
  tibble(
    title = hp_movie_names,
    runtime = 
  )
```

# amazon
```{r}
url = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

# these are reviews from the first page only

dynamite_html = read_html(url)

review_titles = 
  dynamite_html %>%
  html_nodes(".a-text-bold span") %>%
  html_text()

review_stars = 
  dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = 
  dynamite_html %>%
  html_nodes(".review-text-content span") %>%
  html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)

```


# using API

Use GET. content() make s guess about how table is supposed to look like and make csv file
```{r}
nyc_water_df = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.csv") %>% 
  content()
```

# json gives you brackets and stuff. requires additional parsing. So csv is easier to use
```{r}
nyc_water_df = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()
```


```{r}
brfss_smart2010 = 
  GET("https://data.cdc.gov/api/views/acme-vg9e/rows.csv?accessType=DOWNLOAD") %>% 
  content("parsed")
```

```{r}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>%
  content()

poke
poke$name
poke$height
poke$abilities
```

